İnsan müdahalesini azaltarak özellikle güvenlik ve verimlilik açısından önemli avantajlar sunan otonom araçların, gerçek dünya koşullarındaki karmaşık ve öngörülemeyen çevresel faktörlerle başa çıkabilme yeteneklerinin geliştirilmesi gerekmektedir. Bu çalışma, engelleri algılama ve hedefe yönlendirme yeteneklerini entegre eden, otonom araçların bu zorlukları aşmasına yardımcı olacak basitleştirilmiş bir model önermektedir. Model, algılama mekanizmaları aracılığıyla elde edilen verileri analiz ederek test senaryolarında engelleri tespit etmekte ve hedefe doğru yönelmektedir. Bu, otonom araçların güvenli ve etkin bir şekilde yollarını bulma yeteneklerini artırarak, gerçek hayatla bağdaştırıldığında trafik kazalarının azalmasına, ulaşım maliyetlerinin düşmesine ve genel yaşam kalitesinin iyileşmesine katkıda bulunabilir. Biz de altı temel modüle sahip, çevresini algılayabilen, karar verebilen ve rotasını iyileştirebilen bu otonom araç modelini tasarlarken bu gibi durumlardan yola çıktık.
Anahtar Kelimeler: Otonom araç, çevresel algılama, engel tespiti, hedef yönlendirme, renk algılama, gerçek dünya simülasyonu.

Giriş
Teknolojinin hızla geliştiği günümüz dünyasında, otonom araçlar, ulaşım sektöründe devrim yaratma potansiyeline sahiptir. Bu yenilikçi araçlar, insan müdahalesine daha az ihtiyaç duyarak, güvenlik, verimlilik ve erişilebilirlik açısından önemli avantajlar sunmaktadır. Ancak, otonom araçların gerçek dünya koşullarında etkili bir şekilde çalışabilmesi için, karmaşık ve öngörülemeyen çevresel faktörlerle başa çıkabilme yeteneği hayati önem taşımaktadır. Bu çalışma, engelleri algılama ve hedefe yönlendirme yeteneklerini bütünleştirerek, otonom araçların bu zorlukların üstesinden gelmesine yardımcı olacak basitleştirilmiş bir model sunmaktadır.
Otonom araçlar sayesinde yolda önceden beklenmeyen durumlar ile mevcut navigasyon sistemlerine göre daha iyi başa çıkılabilir. Gerçek dünya senaryoları ani durum değişiklikleri ve beklenmeyen engeller içerdiğinden bu oldukça önemli bir avantajdır. Bu çalışmanın amacı, bu tür dinamik ve belirsiz ortamlarda etkin bir şekilde yolunu bulabilen bir otonom araç modeli geliştirmektir. Modelimiz, çevresel algılamaları ve stratejik karar verme süreçlerini dengede tutarak, aracın çevresindeki engelleri algılamasını ve bu engelleri aşarak belirlenen hedefe ulaşmasını sağlar.
Bu model, çeşitli algılama mekanizmaları aracılığıyla çevresel verileri toplar ve bu verileri analiz ederek hem engelleri algılamak hem de hedefe yönlendirmek için kullanır. Engeller ve hedefler, test senaryolarında rastgele oluşturulan koşullarda denenir, böylece modelin gerçek dünyaya benzer karmaşık durumlarla başa çıkma yeteneği değerlendirilir.
Bu değerlendirmeler sadece araçlarla sınırlı değildir, gündelik hayatta karşımıza çıkan birçok örnekte bu modellemede ele alınan durumu görebiliriz. Burada üstünde durmak istediğimiz konu, belleğini, deneyimlerini ve kendi geliştirdiği problem çözme yeteneğini kullanabilen ve bunları hareketlerine yansıtabilen otonom bir ajan yaratmaktır ve bu ajan karar mekanizmasına sahip olduğundan en çok da canlılarla ortak özelliklere sahiptir.

MODEL
Genel Bakış
Modelimiz, bir 'Dünya' ortamında hareket eden ve çevresindeki engelleri algılayıp bu engellere tepki veren bir 'Ajan' içerir. Modelimizde hareket, karar verme, öğrenme ve algılama modüllerinden farklı olarak tahmin ve optimizasyon modüllerine yer verdik. Bu modüller birlikte çalışarak ajanın otonom hareketini sağlarlar. Ajanın temel amacı, belirlenen bir hedefe, engelleri algılayarak ve bunlardan kaçınarak ulaşmaktır. Kilit nokta ajanın başlangıçta hiçbir bilgiye sahip olmamasıdır, tüm bilgileri kendi deneyimleyerek edinir ve belleğine ekler.

Dünya ve Engel Tanımı
'Dünya' sınıfı, ajanın hareket ettiği ortamı temsil eder. Bu ortam belirli bir genişlik ve yüksekliğe sahiptir ve içinde rastgele konumlandırılmış engeller bulunur. Her engel, dünyanın içinde belirli bir konuma yerleştirilir ve bu engeller ajanın hareketini sınırlar. Bu engeller dünyaya eklenirken hiçbir nesnede çakışma olmamasına önem verilir.

Ajan ve Algılama
 Ajan, 'Object' sınıfından türetilmiştir ve x, y koordinatları ile bir yöne sahiptir. Ajanın algılama fonksiyonu, 360 derecelik bir açıda ve belirli bir algılama mesafesi içinde çevresini tarar. Algılanan her nesne, engel veya hedef olabilir ve bu bilgi, ajanın karar verme sürecinde kullanılır. Bu bilgiye erişirken ajan renk özelliklerini kullanır. Çevresindeki nesnelerin renklerini görebilir ve eğer kırmızıysa engel, siyahsa hedef olduğuna karar verir. Kolaylık açısından dünya sınırlarının dışını da kırmızı olarak belirledik ve bu sayede ajan dışarı çıkmaya yaklaştığında aynı engellerde olduğu gibi geri çekilebilme özelliğine sahiptir. Psikolojik açıdan değerlendirdiğimizde ise araç için kırmızı renk korku duygusu uyandırır demek mümkündür. 

Öğrenme ve Tahmin Modülü
Öğrenme ve Tahmin Modülü, ajanın çevresel verileri toplayarak ve bu verileri analiz ederek engelleri ve hedefleri sınıflandırmasını sağlar. Bu modüller, Stochastic Gradient Descent (SGD) sınıflandırıcısını kullanarak, ajanın karar verme sürecinde önemli rol oynar. Modül, engeller ve hedefler için ayrı ayrı eğitilerek, her iki tür nesnenin algılanması ve tahmini üzerinde uzmanlaşır. 
SGDClassifier, lineer sınıflandırıcıların etkili bir şekilde eğitilmesini sağlayan bir makine öğrenimi algoritmasıdır. Bu algoritma, her iterasyonda küçük veri gruplarını kullanarak modeli günceller, bu da büyük veri kümeleri üzerinde çalışırken hız ve verimlilik avantajı sağlar. SGD, hata gradyanını hesaplayarak ve bu gradyanı kullanarak modelin ağırlıklarını güncelleyerek çalışır. Bu süreç, modelin hedef ve engelleri doğru bir şekilde sınıflandırmasını sağlamak için veri üzerinde tekrar tekrar gerçekleştirilir. Bu algoritmanın tekrarlanması optimizasyon modülüne destek olur.
Eğitim süreci, ajanın algıladığı engeller ve hedefler üzerinden gerçekleşir. Ajan, çevresindeki nesneleri algıladıkça, bu veriler öğrenme modülüne gönderilir. Her bir nesne, belirli özellikler (örneğin, konum, boyut, renk) içeren bir veri noktası olarak temsil edilir. Bu veri, SGDClassifier'a beslenir ve model bu veri üzerinde kısmi eğitim (partial fit) gerçekleştirir. Model, engelleri '1' (varlık) veya '0' (yokluk) olarak sınıflandırırken, hedef için benzer bir sınıflandırma yapar.
Model, yeni veri noktaları geldikçe sürekli olarak güncellenir ve iyileştirilir. Bu, ajanın dinamik bir ortamda sürekli olarak öğrenmesini ve adaptasyonunu sağlar. Ajan, yeni bir nesne algıladığında, öğrenme modülü bu nesnenin engel mi yoksa hedef mi olduğuna karar verir ve bu bilgiyi ajanın karar verme sürecine iletir.

Optimizasyon Modülü 
Optimizasyon Modülü, ajanın karşılaştığı engelleri ve hedefi dikkate alarak en uygun yolu belirler. Bu modül, ajanın karar verme sürecinde önemli bir role sahiptir ve ajanın hedefe en etkili şekilde ulaşmasını sağlamak için yolları optimize eder.
Bu modül, ilk olarak mevcut durumu değerlendirir ve ajanın hedefe ulaşması için potansiyel yolları belirler. Bu yollar, engellerin konumlarına, ajanın mevcut konumuna ve hedefin yerine göre hesaplanır. Daha sonra, bu yolların her biri, başarı şansı ve etkinlik açısından değerlendirilir. Değerlendirme süreci, yolun uzunluğu, engellere olan yakınlığı ve hedefe olan mesafeyi dikkate alarak yapılır.
Optimizasyon modülü, başarısız veya verimsiz bulunan yolları optimize etmek için çeşitli stratejiler kullanır. Bu, yolların yeniden sıralanması, engellere daha az yaklaşacak şekilde rotanın ayarlanması veya alternatif yolların keşfedilmesi şeklinde olabilir. Bu süreç, ajanın karşılaştığı engeller ve hedef konumuna göre dinamik bir şekilde uyarlanır.
Ajanın karşılaştığı duruma bağlı olarak, optimizasyon modülü farklı karar verme stratejileri uygular. Eğer ajan, hedefe ulaşmak için net bir yol bulamazsa, modül, deneme-yanılma yöntemleri veya geri bildirim döngüleri kullanarak yeni yollar oluşturabilir ve test edebilir. Bu süreç, ajanın hedefe ulaşma şansını maksimize etmek ve engellerden etkili bir şekilde kaçınmak için sürekli olarak güncellenir.
Bu modül ajanın deneyimleri ne kadar fazlaysa o kadar iyi çalışır, bu nedenle başlangıçta rota hesaplama konusunda istenen başarıyı elde etmesi zordur ve konumlar rastgele belirlendiğinden tahmin edilemez. Fakat zaman geçtikçe ajanın konumlar hakkında edindiği bilgiler sayesinde rota iyileştirilir. Bunun örneklerini de test ettiğimiz koşul1’de gözlemlemek mümkündür, 5’in katları olan denemelerde başarıya yaklaşılmasında bu modülün etkisi olmuştur. Her çalıştırdığımızda deneyimleri arttığından bir önceki denemeye göre daha iyi bir performans göstereceğinden neredeyse emin olabiliriz. 

Karar Verme ve Hareket
Ajan, algıladığı verilere dayanarak karar verme fonksiyonu aracılığıyla kararlarını verir. Bu kararlar, engellerden kaçınma, hedefe doğru hareket etme veya belirlenen bir hedefe doğru ilerleme şeklinde olabilir. Karar verildikten sonra, ajan hareket fonksiyonu aracılığıyla hareket eder ve bu hareket, algılanan engeller ve hedefe göre ayarlanır. Araç hareket esnasında ilk çalıştırmada dünyayı bilmediğinden hedefin olduğunu düşündüğü rastgele bir konuma yönlenir ve orada hedef yoksa farklı bir konum belirler ve algoritma bu şekilde devam eder. Dünyayı öğrenmeye başladığında ise tahmin modülü tahmin yapabilir duruma gelir ve hareket esnasında bu tahmin sonuçları kullanılır. Tüm bunların sonucu olarak, 100 deneme içeren koşullarda neden başlangıç denemelerinde genel olarak hedefe ulaşılamadığı anlaşılmış olur
Hedefe Ulaşma
Ajanın asıl amacı, belirlenen hedefe ulaşmaktır. Bu, algılanan hedefin konumuna göre hareket ederek ve engellerden kaçınarak gerçekleştirilir. Ajan, hedefe ulaştığında başarılı bir sonuca ulaşır. Özellikle başlangıçta başarısızlık oranlarının fazla olduğunu bildiğimiz için bir denemedeki hareketi 100 kereyle sınırlandırdık. Yine de rastgele konumlardan dolayı testlerimiz sırasında bazen hedefe uygun bir noktada başlayıp 10 hamle içerisinde başarıya ulaştığını da gözlemleyebildik ama bu durum oldukça nadir olarak karşımıza çıktı.

Modüllerin Bağlantısı
Tüm modüllerin birbirleriyle bilgi alışverişi gerçekleştirmesi oldukça önemlidir, bu nedenle modelimizde özellikle bağlantıların üstünde durduk. Algı modülünün bilgisini tüm modüller kullanır çünkü hepsinin aracın deneyimlerine ihtiyacı vardır. Hareket ve karar verme modülleri ise oldukça bağlantılıdır çünkü algı modülünün bilgisiyle elde edilen karar hareket modülüne gönderilir ve nasıl bir hareket izleneceği bu sayede belirlenmiş olur. Tahmin ve öğrenme modülleri birlikte çalışır diyebiliriz ve öğrenme modülünde işlenen bilgiler tahmin modülünde detaylandırılır ve uygun koordinat tahminleri yapıldığında bu bilgiyi hareket modülünün kullanması sağlanır. Optimizasyon modülünden gelen bilgi ise hareket modülünde kullanılır ve hedefe olan rotanın optimize edilmesi dolayısıyla da hareket süresinin kısalması hedeflenir. Özetleyecek olursak, modüller birbirlerinden oldukça bilgi aldığından tüm modüllerin bağlantılarının eksiksiz olması modelin düzgün çalışmasını sağlayan en önemli noktadır. 

Test
Modelimizin performansını değerlendirmek için iki farklı koşul altında bir dizi simülasyon gerçekleştirilecektir. Bu koşullar, ajanın engelleri algılama ve hedefe ulaşma yeteneğini farklı senaryolarda test etmek için tasarlanmıştır.

Koşul 1
Bu koşul, ajanın öğrenme kabiliyetini ve aynı senaryoya adaptasyonunu test eder. Aynı engel ve hedef düzenlemeleriyle karşılaştıkça, ajanın zaman içinde daha etkili yollar bulması ve hedefe daha hızlı ulaşması beklenir.

Koşul 2 
Bu koşulda, her denemede nesnenin, engellerin ve hedefin konumu rastgele belirlenir.
Bu, her denemede ajanın yeni ve öngörülemeyen senaryolarla karşılaşmasını sağlar.
Bu koşul, ajanın yeni ortamlara ne kadar hızlı ve etkili bir şekilde uyum sağlayabildiğini test eder. Her yeni denemede, ajanın karar verme ve navigasyon stratejilerini yeniden değerlendirmesi ve optimize etmesi gerekecektir.

Test Algoritmaları ve Beklenen Sonuçlar
Her iki koşulda da ajanın algılama, karar verme ve hareket etme algoritmaları aynı kalacak, ancak karşılaştığı senaryolar değişecektir.
Koşul 1'de, ajanın tekrarlanan denemelerle daha verimli hale gelmesi ve hedefe daha hızlı ulaşması beklenir. Bu, öğrenme ve adaptasyon mekanizmalarının etkinliğini gösterir.
Koşul 2'de ise, ajanın her denemede yeni ve benzersiz engel düzenlemelerine uyum sağlaması gerekecektir. Bu durumda, ajanın genel başarımı, çevresel adaptasyon yeteneğine ve karşılaştığı her yeni senaryoya hızlı bir şekilde nasıl yanıt verebildiğine bağlı olacaktır.
Sonuç Değerlendirme:
Performans, ajanın hedefe ulaşma süresi, alınan yolun uzunluğu ve engellerle olan etkileşim sayısı gibi metriklerle değerlendirilecektir.

Test Sonuçları
Her iki koşulun sonuçlarını modelimizde karşılaştırdığımızda belirgin farklar ortaya çıktı. İlk koşul altında 5’in katı olan denemelerde model olabildiğince öğrenmesini tamamladığından başta hedefe hiç ulaşamıyorken sonlarda kısa sürede ulaşmaya başladı. Aynı koşul altında her ne kadar rastgele bir düzen olsa da son denemelere yaklaşıldıkça modelin performansının genel olarak arttığını gözlemledik ve bu ulaşmak istediğimiz bir sonuçtu. İkinci koşul altında ise araç öncekilerdeki bilgilerden dolayı yanlış tahminlerde bulunabiliyor. Çünkü önceki deneyimlerini belleğinde tuttuğunda diğer deneme sırasında orada engel olmasa da olduğunu düşündüğünden hareketi etkileniyor. 
Modelin gerçekçiliği açısından incelendiğinde aslında bu durumun normal olduğu sonucuna vardık. Çünkü model aynı canlılarda olduğu gibi belirli bir bilgi ona verildikten sonra bundan etkilenme eğiliminde oluyor ve bu da sonraki hareketine yansıyor. Biz bunu psikolojik deneylerde karşımıza çıkan sonuçlarla bağdaştırdık. Her ne kadar farklılıklar olsa da aslında “öğrenilmiş çaresizlik” durumuna benzer bir hareket sergiliyor. Örneğin; hedefin bir noktada olmadığını gördükten sonra diğer deneme sırasında değiştiğini bilse de deneyimleri oraya gitmeme yönelimi göstermesine sebep oluyor. 


 

Şekil 1: Koşul 1 altındaki 100 denemenin başarı oranları


 
  Şekil 2: Koşul 2 altındaki 100 denemenin başarı oranları

Sonuç
Bu çalışmada, otonom araçların karmaşık ve değişken çevresel koşullarda etkin bir şekilde hareket etmesini sağlamak amacıyla bir model geliştirdik. Modelimiz, 'Dünya', 'Ajan', Öğrenme Modülü, Tahmin Modülü ve Optimizasyon Modülü gibi bileşenleri içerir ve bu bileşenlerin birbiriyle etkileşimi sayesinde ajanın hedefe ulaşmasını sağlar.
Modelimizin temel özelliği, ajanın başlangıçta çevresel koşullar hakkında hiçbir bilgiye sahip olmaması ve bu bilgileri kendi deneyimleri aracılığıyla edinmesidir. Bu süreç, SGDClassifier kullanılarak gerçekleştirilen öğrenme ve tahmin mekanizmaları ile desteklenir. Ajan, çevresindeki nesneleri renklerine göre algılar ve bu bilgileri engel ve hedefi sınıflandırmak için kullanır. Öğrenme süreci boyunca ajan, çevresindeki nesneler hakkında daha fazla bilgi edinir ve bu bilgileri gelecekteki hareketlerinde kullanır.
Optimizasyon Modülü, ajanın hedefe ulaşmak için izleyeceği rotayı belirler ve bu rotayı sürekli olarak optimize eder. Bu modül, ajanın karşılaştığı duruma bağlı olarak farklı stratejiler uygular ve ajanın hedefe ulaşma şansını artırır.
İki farklı koşul altında gerçekleştirilen testler, modelimizin performansını değerlendirmemizi sağladı. Koşul 1'de, ajanın aynı çevresel koşullara maruz kaldığı ve bu koşullara adaptasyonunu test ettik. Sonuçlar, ajanın tekrarlanan denemelerle performansını artırdığını gösterdi. Koşul 2'de ise, her denemede çevresel koşulların rastgele belirlendiği ve ajanın bu yeni koşullara adaptasyonunu test ettik. Bu koşul, ajanın çevresel değişikliklere hızlı bir şekilde yanıt verebilme yeteneğini ortaya koydu.
Genel olarak, modelimiz, otonom araçların gerçek dünya koşullarında karşılaşabileceği engelleri algılama ve bunlardan kaçınarak hedefe ulaşma yeteneğini gösterdi. Ayrıca, modelin öğrenme ve adaptasyon yetenekleri, karmaşık ve öngörülemeyen çevresel koşullara etkili bir şekilde yanıt verebilmesini sağladı.
Sonuç olarak, bu çalışma, otonom araçların gelişimine önemli bir katkı sağlayabilir ve bu araçların güvenliği ve etkinliğini artırmada önemli bir rol oynayabilir. Ayrıca, bu modelin geliştirilmesi ve farklı senaryolarda test edilmesi, otonom araç teknolojisinin daha da ilerlemesine yardımcı olacaktır. Bu model, karmaşık çevresel koşullara uyum sağlayabilen, etkili bir şekilde öğrenebilen ve hedefe ulaşmak için gerekli stratejileri geliştirebilen otonom araçların geliştirilmesi için sağlam bir temel oluşturmaktadır.

Psikolojik Değerlendirme
Modelimizin psikolojik açıdan değerlendirilmesi, otonom araçların karar verme süreçlerini anlamak için önemli bir perspektif sunar. Modelde, ajanın çevresel koşullara adaptasyonu ve öğrenme süreci, insan psikolojisinin bazı yönlerini yansıtır. Özellikle, ajanın algıladığı engellerin renklerine göre farklı tepkiler vermesi, insanların duygusal ve bilişsel tepkilerine benzer bir mekanizmayı andırır. Örneğin, kırmızı renk genellikle tehlike veya uyarı anlamına gelir ve modelimizde ajan, kırmızı renkli engelleri algıladığında kaçınma tepkisi gösterir. Bu, insanların renklerle ilişkilendirdikleri duygusal tepkilerle paralellik gösterir.
Ayrıca, ajanın öğrenme süreci, insanların deneyimlerden öğrenme ve bu öğrenmeleri gelecekteki kararlarında kullanma sürecine benzer. Ajan, tekrarlanan denemeler boyunca çevresel koşullar hakkında bilgi toplar ve bu bilgiyi, gelecekte karşılaşabileceği benzer durumlarla başa çıkmak için kullanır. Bu süreç, insanların geçmiş deneyimlerden ders çıkararak gelecekte daha iyi kararlar almasına benzer bir mekanizma sergiler.
Modelin optimizasyon süreci ise, insanların karşılaştığı problemlere çözüm bulma ve bu çözümleri sürekli olarak iyileştirme eğilimini yansıtır. Ajan, karşılaştığı engelleri ve hedefi dikkate alarak en uygun yolu belirler ve bu yolun başarısız olduğu durumlarda alternatif stratejiler geliştirir. Bu, insanların karşılaştıkları zorluklar karşısında esnek olma yeteneklerine benzer.
Son olarak, ajanın her yeni denemede farklı senaryolara adaptasyonu, insanların değişen çevresel koşullara uyum sağlama kabiliyetini yansıtır. Her yeni denemede, ajanın karşılaştığı duruma göre farklı kararlar alması ve bunları uygulaması, insanların değişen koşullara hızlı bir şekilde yanıt verme ve uyum sağlama yeteneğine paraleldir.
Bu psikolojik açıdan yapılan değerlendirme, modelimizin insan davranış ve karar verme süreçlerine benzer yönler taşıdığını göstermektedir. Bu benzerlikler, otonom araçların insan benzeri karar verme süreçlerini taklit ederek daha etkili ve güvenli bir şekilde hareket etmesini sağlayabilir. Bu nedenle, modelimizin psikolojik açıdan incelenmesi, otonom araçların gelişimine önemli katkılarda bulunabilir.
Referanslar
P. Baldi, "Gradient descent learning algorithm overview: a general dynamical systems perspective," in IEEE Transactions on Neural Networks, vol. 6, no. 1, pp. 182-195, Jan. 1995, doi: 10.1109/72.363438.

